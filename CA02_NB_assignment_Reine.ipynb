{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCZYXwtCsL_y"
      },
      "source": [
        "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
        "\n",
        "In this assignment you will ...\n",
        "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
        "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
        "\n",
        "IMPORTANT NOTE:\n",
        "\n",
        "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "4p_DvtT7sOIr",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "import os \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "from collections import Counter \n",
        "\n",
        "# Import all other necessary libraries. Your code below ...\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* import os: This code imports the \"os\" module, which makes it possible to use and interact with the operating system dependent functionality, and thus be able to perform different operations, such as creating a directory, launching new processes, reading and/or writing files.\n",
        "\n",
        "* import numpy as np: This code imports the numpy (Numerical Python) library and assigns the alias \"np\" to the library. This library makes it possible to carry out mathematical and scientific operations on arrays of data for proper data analysis. This library also makes it possible to generate random numbers, perform linear algebra operations, as well as array indexing.\n",
        "\n",
        "* from collections import Counter: This code imports Counter from the collections module. Counter counts the elements and the output is in form of a key, value pair indicating the number of times every element appears in a list, string, or dictionary.\n",
        "\n",
        "\n",
        "* from sklearn.naive_bayes import GaussianNB: This code is used to import the Gaussian Naive Bayes algorithm for classification as one of the 3 main types of Naive Bayes algorithms (The other two are Multinomial and Bernoulli).It's being imported from the \"sklearn\" library, which incorporates numerous machine learning algorithms and other functions that are useful for machine learning, such evaluating how well a model performs and splitting the data into training data and test data.\n",
        "\n",
        "* from sklearn.metrics import accuracy_score: This code imports the accuracy_score function from the  \"sklearn\" library, which consists of various tools that are used in machine learning to asses the performance of models. The accuracy_score is one of these tools, and it calculates the accuracy of a model's predictions. "
      ],
      "metadata": {
        "id": "1F70RCVvSn21"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "jjKF0nIMwz8_",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def make_Dictionary(root_dir):\n",
        "  all_words = []\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words\n",
        "  dictionary = Counter(all_words)\n",
        "  list_to_remove = list(dictionary)\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False:\n",
        "      del dictionary[item]\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item]\n",
        "  dictionary = dictionary.most_common(3000)\n",
        "  return dictionary\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   The above code creates a new function called \"make_Dictionary\", which accepts  only one argument â€“ \"root_dir\". The \"root_dir\" argument represents the path where the data folders containing the emails are located. Thus, the first line uses \"def\" to define this function that's being created.\n",
        "\n",
        "*   On the next line, \"all_words = []\", an empty list called \"all_words\" is created. Later on, this list will be used to store all the words that were found in the emails. \n",
        "\n",
        "*   The function proceeds by using the \"os.path.join\" method with the argument \"root_dir\" to create a list of file paths, called \"emails\", containing all the files in the \"root_dir\" directory, as seen in the code \"for f in os.listdir(root_dir)\". The os.listdir() method is used to get the list of all files in the \"root_dir\" directory, while \"for f\" introduces a for loop to get each file separately.\n",
        "\n",
        "\n",
        "*   The function then proceeds by using a for loop to indicate that for every \"mail\" file (every email) in the \"emails\" list, the function opens the file using the open () function combined with the \"with\" statement. From there, a for loop is used to iterate through every line in the file. Under this for loop, the \"line.split()\" method is used to split every line into a list of words, and then the statement \"all_words += words\" is used to store the words in the \"all_words\" empty list that was created at the beginning. \n",
        "\n",
        "*   Using the \"Counter\" method that was imported from the \"collections\" library at the very beginning, a variable, \"dictionary\", is created. Under this new variable, the \"Counter\" method takes the \"all words\" list as an argument and makes a dictionary which shows the number of times every word appears. That is, using the key-value format, the keys represent the words, while the values indicate the number of times that specific word appears. Next, the list() function takes the \"dictionary\" variable that was previously created and a list called \"list_to_remove\" is created. This list contains all the words (keys) of the dictionary.\n",
        "\n",
        "\n",
        "*   Next, a for loop is introduced to iterate through every item of the \"list_to_remove\" list. Here, the if statement together with the .isalpha() method are used to verify whether the item is alphabet or not. If it is not, the item is deleted from the dictionary using the \"del dictionary[item]\" statement. The elif statement is then used to check whether the length of the item, \"len(item)\" is 1. If this isn't the case, the item is deleted from the dictionary using \"del\" dictionary[item]. \n",
        "\n",
        "*   In the last two lines of code, the \"most_common()\" method is used on \"dictionary\" to return the 3,000 most common words in the dictionary, and finally returns the dictionary.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FESbiJ2n2lmb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "dmVW5xNlyOFc",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def extract_features(mail_dir):\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "  features_matrix = np.zeros((len(files),3000))\n",
        "  train_labels = np.zeros(len(files))\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in files:\n",
        "    with open(fil) as fi:\n",
        "      for i, line in enumerate(fi):\n",
        "        if i ==2:\n",
        "          words = line.split()\n",
        "          for word in words:\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary):\n",
        "              if d[0] == word:\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word)\n",
        "      train_labels[docID] = 0;\n",
        "      filepathTokens = fil.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "  return features_matrix, train_labels                "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above create a function called extract_features.\n",
        "\n",
        "*   At the beginning of the code \"def\" is used to define the function, \"extract_features()\", which accepts \"mail_dir\" as its only argument. \"mail_dir\" is the directory where all the email files are stored. On the next line, a list called \"files\" is created using a list comprehension. The list has the file paths of the files that are stored in the \"mail_dir\" directory. Specifically, to create this list of file paths, the \"extract_features()\" function joins the directory path with the names of the files in the directory. To do so, the os.path.join() and os.listdir() methods are used to combine the directory path with the names of the files in the directory and then get a list of the files in the \"mail_dir\" directory. \n",
        "\n",
        "*   Next, a numpy array called \"feature_matrix\" is created by using np.zeros((len(files),3000)). The use of np.zeros() means that the array will only contain zeros and the shape of that array will be the length of the files (number of files) and 3000 dimensions, which is why the np.zeros() function has len(files),3000)) as its shape. Similarly, on the next line, the same numpy function is applied to create a numpy array called \"train_labels\" that will contain zeros and its shape/length will be that of the number of files - len(files) - which was also used to help determine the shape of the \"feature_matrix\" array.\n",
        "\n",
        "\n",
        "*  The \"extract_features\" function then uses a for loop to iterate every file in the \"files\" list. The for loop begins by using the \"with\" statement with the \"open()\" function to open the file, and then another for loop which goes through every line of the file is introduced.Python's enumerate() is used to assign a counter to each file. This is important because in the next line an if-statement is introduced where for the third line of every file, the line is split into words using line.split() method and assigned to a new variable called \"words\". Another for loop that checks whether the word exists in the \"dictionary\" is used. If the word exists, the number of times the word appears in the \"words\" variable that was previously created is added to the corresponding column in the \"feature_matrix\". This done by using the count() method to count the number of times the word appears. \n",
        "\n",
        "*   The defined function proceeds by assigning \"0\" to the email. However, the following if statement indicates that if the name of the file starts with \"spmsg\", a label of \"1\" instead of \"0\" will be assigned to it under the variable \"train_labels\".\n",
        "\n",
        "* Finally, the variables \"count\" and \"docID\" are updated with an increment of 1 \"count + 1\" and \"docID + 1\", meaning the new value will be based on the last value plus 1. The function then returns the \"feature_matrix\" and \"train_labels\".\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BWd6sk9xB6Hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyXiCGzoDUWW",
        "outputId": "3f8db2c5-4f75-4f07-8fb8-fd37d584d206"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above is used to allow this particular Colab notebook to access the files in my Google Drive. This code isn't needed for the Naive Bayes machine learning algorithm. However, I added it because this notebook and the folders for the \"train-mails\" and \"test-mails\" are located in my Google Drive. So to avoid getting an error indicating that the folders \"train_mails\" and \"test_mails\" don't exist, I had to add the above two line of code."
      ],
      "metadata": {
        "id": "ePxabnyVDhJc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "zoq-rE7Mx0pp",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Enter the \"path\" of your \"train_mails\" and \"test-mails\" FOLDERS in this cell ...\n",
        "# for example: TRAIN_DIR = '../../train-mails'\n",
        "#              TEST_DIR = '../../test-mails'\n",
        "TRAIN_DIR = '/content/drive/My Drive/Colab Notebooks/train-mails'\n",
        "TEST_DIR = '/content/drive/My Drive/Colab Notebooks/test-mails'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variable \"TRAIN_DIR\" is the data that's used to train the model, while \"TEST_DIR\" is the variable with the data that's used to test/evaluate the performance of the model. "
      ],
      "metadata": {
        "id": "TxFIqljY2DZt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "134lmhauyQxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816dc4de-0523-4116-e69d-bd48187205ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n"
          ]
        }
      ],
      "source": [
        "dictionary = make_Dictionary(TRAIN_DIR)\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extract_features(TRAIN_DIR)\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The first line in the code above uses a custom made function called \"make_Dictionary\" to create a dictionary from the emails in the folder \"train-mails\" that are under the variable \"TRAIN_DIR\".\n",
        "\n",
        "* The next line prints the message provided in the parentheses and double quotation marks to indicate that the program is reading and processing the emails from the train and test folders.\n",
        "\n",
        "* The \"extract_features\" function, which was previously defined, takes the \"TRAIN_DIR\" variable, which is the folder with the training emails, and extracts the needed features as they were defined when this function was being created. For instance, labeling the emails â€” train_labels â€” and counting the number of times a word appears â€” words.count(word). The \"extract_features\" function then returns a tuple that consists of the features_matrix and labels. It's a tuple because the function returns more than one value that's separated by a comma.\n",
        "\n",
        "* Similarly, on the last line, the \"extract_features\" function is used, but this time on the emails in the test-mails folder under the \"TEST_DIR\" variable. "
      ],
      "metadata": {
        "id": "xycmY_LTvc_V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91757b99-9eee-4d9d-d0d6-783dce1686d3",
        "id": "_Y9vy-0nq_hM"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model using Gaussian Naive Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9653846153846154\n"
          ]
        }
      ],
      "source": [
        "# In this section enter your code to TRAIN the model using Naive Bayes algorithm, then PREDICT and then evaluate PERFORMANCE (Accuracy)\n",
        "# Your code below ...\n",
        "# Your output should look like below if your code is right\n",
        "model = GaussianNB()\n",
        "print (\"Training Model using Gaussian Naive Bayes algorithm .....\")\n",
        "#training model\n",
        "model.fit(features_matrix, labels)\n",
        "print (\"Training completed\")\n",
        "print (\"testing trained model to predict Test Data labels\")\n",
        "predicted_labels = model.predict(test_features_matrix)\n",
        "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print (accuracy_score(test_labels, predicted_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The code above begins by assigning \"GaussianNB()\" to a variable called \"model\". \"GaussianNB()\" is used to implement the Gaussian Naive Bayes algorithm for classification. \n",
        "\n",
        "* A message indicating that the model is being trained is then printed using print, parentheses, and double quotation marks.\n",
        "\n",
        "* On the next line of code, training the model is done by using the Sklearn .fit() method on the \"model\" variable that was previously created. The method takes two arguments â€” \"features_matrix\", and \"labels\" â€” which correspond to the given dataset. \n",
        "\n",
        "* The next two lines of code print out two messages indicating that the process of training the model is done and now the trained model is predicting the labels for \"test_features_matrix\", as shown in the next line of code where the predict method takes \"test_features_matrix\" as its argument and assigns the predicted labels to \"y_predicted\".\n",
        "\n",
        "* In the last two lines, a message indicating that the classification of the test data has been completed is printed out. Followed by calculating and printing out the accuracy score that's obtained by using the \"accuracy_score\" function to compare the \"test_labels\" (the true labels) and \"predicted_labels\". The accuracy score is one of the ways used to measure the performance of the model. In this case a value of 0.965 indicates that the model correctly predicted the label for 96.5%  of the test data, which is very good."
      ],
      "metadata": {
        "id": "m2mURWCpH0G0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5_mPrvN586A"
      },
      "source": [
        "======================= END OF PROGRAM ========================="
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}